{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "#sales_15 = pd.read_csv('C:/Users/np8022/Desktop/ZS Hack/ADS TT/Inputs/2015_sales_data.csv')\n",
    "#sales_16 = pd.read_csv('C:/Users/np8022/Desktop/ZS Hack/ADS TT/Inputs/2016_sales_data.csv')\n",
    "sales_17 = pd.read_csv('C:/Users/np8022/Desktop/ZS Hack/ADS TT/Inputs/2017_sales_data.csv')\n",
    "sales_18 = pd.read_csv('C:/Users/np8022/Desktop/ZS Hack/ADS TT/Inputs/2018_sales_data.csv')\n",
    "city     = pd.read_json('C:/Users/np8022/Desktop/ZS Hack/ADS TT/Inputs/city_dict.json',typ='Series')\n",
    "e_dis = pd.read_csv('C:/Users/np8022/Desktop/ZS Hack/ADS TT/Inputs/expected_discount.csv')\n",
    "h_dis = pd.read_csv('C:/Users/np8022/Desktop/ZS Hack/ADS TT/Inputs/historical_discount.csv')\n",
    "ff = pd.read_csv('C:/Users/np8022/Desktop/ZS Hack/ADS TT/Inputs/foot_fall.csv')\n",
    "product = pd.read_csv('C:/Users/np8022/Desktop/ZS Hack/ADS TT/Inputs/product_information.csv')\n",
    "test = pd.read_csv('C:/Users/np8022/Desktop/ZS Hack/ADS TT/Inputs/test_data.csv')\n",
    "test_id=pd.read_csv('C:/Users/np8022/Desktop/ZS Hack/ADS TT/Inputs/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city=pd.DataFrame(city)\n",
    "city.reset_index(level=0, inplace=True)\n",
    "city.columns = ['city', 'city_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################            Train data\n",
    "\n",
    "\n",
    "Sales = pd.concat([sales_17,sales_18])\n",
    "Sales_city=Sales.merge(city,how='left',on=['city','city'])\n",
    "h_dis_pd=h_dis.melt(id_vars=[\"date\", \"product\"], \n",
    "        var_name=\"city_name\", \n",
    "        value_name=\"dis\")\n",
    "h_dis_pd['city_name']=h_dis_pd['city_name'].str.replace('Discount_','')\n",
    "Sales_dis=pd.merge(Sales_city,h_dis_pd,how='left',left_on=['date','product','city_name'], right_on = ['date','product','city_name'])\n",
    "Sales_prod=pd.merge(Sales_dis,product,how='left',on=['product','product'])\n",
    "train=Sales_prod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['datetime'] = pd.to_datetime(train['date'])\n",
    "\n",
    "train['weekday'] = train['datetime'].dt.dayofweek\n",
    "train['monthday']= train['datetime'].dt.day\n",
    "train['month']=train['datetime'].dt.month\n",
    "train['year']=train['datetime'].dt.year\n",
    "train['weekend']= train['weekday'].apply(lambda x:1 if x>4 else 0 )\n",
    "#train['sunday_or_monday']= train['weekday'].apply(lambda x:1 if x>5 or x<1 else 0 )\n",
    "#train['hour']= train['datetime'].apply(lambda x:x.hour )\n",
    "#train['peak_hour']=train['hour'].apply(lambda x:1 if x<6 or x>19 else 0)\n",
    "#train['time_filter']=train['hour'].apply(lambda x:1 if x is 2 or x is 4 else 0 )\n",
    "#train['date_filter']=train['monthday'].apply(lambda x:1 if x is 23 or x is 30 else 0 )\n",
    "train.drop(['date','city','dis'],axis=1,inplace=True)\n",
    "train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_train=ff.melt(id_vars=[\"city\"], \n",
    "        var_name=\"datetime\", \n",
    "        value_name=\"ff\")\n",
    "ff_train['datetime'] = pd.to_datetime(ff_train['datetime'])\n",
    "\n",
    "\n",
    "train=train.merge(ff_train,how='left',left_on=['city_name','datetime'],right_on=['city','datetime'])\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['datetime','city'],axis=1,inplace=True)\n",
    "train['product'] = train['product'].astype(object)\n",
    "train.drop(['var_4','var_7'],axis=1,inplace=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat=train.drop(['ff'],axis=1)\n",
    "train_num=train.drop(['product', 'sales', 'city_name', 'product_category',\n",
    "       'product_subcategory', 'var_1', 'var_2', 'var_3', 'var_5', 'var_6',\n",
    "       'var_8', 'var_9', 'var_10', 'weekday', 'monthday', 'month', 'year',\n",
    "       'weekend'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(train_num.values)\n",
    "train_num = imp.transform(train_num.values)\n",
    "train_num=pd.DataFrame(train_num)\n",
    "train_num.columns =['ff']\n",
    "train=train_cat.merge(train_num,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ff_pred=train.drop(['product', 'sales', 'product_category',\n",
    "       'product_subcategory', 'var_1', 'var_2', 'var_3', 'var_5', 'var_6',\n",
    "       'var_8', 'var_9', 'var_10'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ff_pred.drop_duplicates(keep='first',inplace=True)\n",
    "train_ff_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('C:/Users/np8022/Desktop/ZS Hack/ADS TT/Outputs/train_v4(lgb for ff pred_nodis).csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########          Test\n",
    "\n",
    "\n",
    "test_city=test.merge(city,how='left',on=['city','city'])\n",
    "e_dis_pd=e_dis.melt(id_vars=[\"date\", \"product\"], \n",
    "        var_name=\"city_name\", \n",
    "        value_name=\"dis\")\n",
    "\n",
    "e_dis_pd['city_name']=e_dis_pd['city_name'].str.replace('Discount_','')\n",
    "test_dis=pd.merge(test_city,e_dis_pd,how='left',left_on=['date','product','city_name'], right_on = ['date','product','city_name'])\n",
    "test_prod=pd.merge(test_dis,product,how='left',on=['product','product'])\n",
    "test=test_prod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['datetime'] = pd.to_datetime(test['date'])\n",
    "\n",
    "test['weekday'] = test['datetime'].dt.dayofweek\n",
    "test['monthday']= test['datetime'].dt.day\n",
    "test['month']=test['datetime'].dt.month\n",
    "test['year']=test['datetime'].dt.year\n",
    "test['weekend']= test['weekday'].apply(lambda x:1 if x>4 else 0 )\n",
    "#test['sunday_or_monday']= test['weekday'].apply(lambda x:1 if x>5 or x<1 else 0 )\n",
    "#test['hour']= test['datetime'].apply(lambda x:x.hour )\n",
    "#test['peak_hour']=test['hour'].apply(lambda x:1 if x<6 or x>19 else 0)\n",
    "#test['time_filter']=test['hour'].apply(lambda x:1 if x is 2 or x is 4 else 0 )\n",
    "#test['date_filter']=test['monthday'].apply(lambda x:1 if x is 23 or x is 30 else 0 )\n",
    "#test.to_csv('C:/Users/np8022/Desktop/analytics Vidhya competition/JH Demand Forecasting/Outputs/test_download.csv',index=False)\n",
    "#test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ LGB for FF pred, don't use for Arima  ################### \n",
    "\n",
    "\n",
    "\n",
    "test_ff_lgb=test.drop(['id', 'date', 'product', 'dis', 'product_category',\n",
    "       'product_subcategory', 'var_1', 'var_2', 'var_3', 'var_4', 'var_5',\n",
    "       'var_6', 'var_7', 'var_8', 'var_9', 'var_10','datetime','city'],axis=1)\n",
    "test_ff_lgb.drop_duplicates(keep='first',inplace=True)\n",
    "\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "Xd,yd=train_ff_pred.drop('ff',axis=1),train_ff_pred.ff\n",
    "\n",
    "for col in ['city_name']:\n",
    "            Xd[col] = Xd[col].astype('category')\n",
    "            test_ff_lgb[col] = test_ff_lgb[col].astype('category')\n",
    "\n",
    "\n",
    "lgbm_ff = LGBMRegressor()\n",
    "lgbm_ff.fit(Xd,yd)\n",
    "\n",
    "test_ff_lgb['ff']= lgbm_ff.predict(test_ff_lgb)\n",
    "\n",
    "test=test.merge(test_ff_lgb,how='left',on=['city_name','monthday','month','year','weekday','weekend'])\n",
    "test.drop(['id', 'date', 'city','dis','datetime'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ ARIMA for FF pred, don't use for LGB  ###################\n",
    "\n",
    "\n",
    "\n",
    "test_ff=test.drop(['id', 'date', 'city', 'product', 'dis', 'product_category',\n",
    "       'product_subcategory', 'var_1', 'var_2', 'var_3', 'var_4', 'var_5',\n",
    "       'var_6', 'var_7', 'var_8', 'var_9', 'var_10', 'weekday',\n",
    "       'monthday', 'month', 'year', 'weekend'],axis=1)\n",
    "\n",
    "test_ff_unq=test_ff.groupby(['city_name','datetime']).size().reset_index().rename(columns={0:'count'})\n",
    "test_ff_unq.drop('count',axis=1,inplace=True)\n",
    "test_ff_unq=test_ff_unq.sort_values(by=['datetime','city_name'])\n",
    "\n",
    "ff_pd=ff.melt(id_vars=[\"city\"], \n",
    "        var_name=\"date\", \n",
    "        value_name=\"ff\")\n",
    "ff_pd=ff_pd.sort_values(by=['date','city'])\n",
    "\n",
    "ff_pd['datetime'] = pd.to_datetime(ff_pd['date'])\n",
    "ff_pd.drop(['date'],axis=1,inplace=True)\n",
    "ff_pd.set_index('datetime',inplace=True)\n",
    "ff_pd=ff_pd.dropna()\n",
    "\n",
    "city_list=ff_pd['city'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "\n",
    "ff_test_pred= pd.DataFrame(columns=['date','city', 'ff'])\n",
    "\n",
    "for item in city_list:\n",
    "    train_model=ff_pd[ff_pd['city']==item]\n",
    "    test_filtered=test_ff_unq[test_ff_unq['city_name']==item]\n",
    "    train_model.drop('city',axis=1,inplace=True)\n",
    "\n",
    "#final_table= pd.DataFrame(columns=['Course_ID', 'Sales', 'Day_No'])\n",
    "#Day_No=range(883,943)\n",
    "#for ID in range(1,139):\n",
    "#    train_time=train_date[train_date['Course_ID']==ID]\n",
    "#    train_time=train_time[['date','Sales']]\n",
    "#    train_time['date'] = pd.to_datetime(train_time['date'])\n",
    "#    train_time.set_index('date',inplace=True)\n",
    "   \n",
    "    model = auto_arima(train_model, start_p=1, start_q=1,\n",
    "                           max_p=3, max_q=3, m=7,\n",
    "                           start_P=0, seasonal=True,\n",
    "                           d=1, D=1, trace=True,\n",
    "                           error_action='ignore',  \n",
    "                           #parallel=True,n_jobs=8,\n",
    "                           suppress_warnings=True, \n",
    "                           stepwise=True)\n",
    "    print(model.aic())\n",
    "    print(item)\n",
    "    model.fit(train_model)\n",
    "    \n",
    "    \n",
    "    forecast = model.predict(n_periods=len(test_filtered))\n",
    "    \n",
    "    s=pd.DataFrame({'date':test_filtered.datetime,'city':test_filtered.city_name,'ff':forecast})\n",
    "    #print(s)\n",
    "    ff_test_pred=ff_test_pred.append(s,ignore_index=True)\n",
    "\n",
    "ff_test_pred.to_csv('C:/Users/np8022/Desktop/ZS Hack/ADS TT/Outputs/Sarimax 7 v1.csv',index=False)\n",
    "\n",
    "    \n",
    "    #forecast = pd.DataFrame(forecast,index = (883:942),columns=['Prediction'])\n",
    "#print(train_time.head())\n",
    "#train_time.dtypes\n",
    "\n",
    "test=test.merge(ff_test_pred,how='left',left_on=['city_name','datetime'],right_on=['city','date'])\n",
    "test.drop(['id','datetime','date_x','city_x','dis','date_y','city_y'],axis=1,inplace=True)\n",
    "test['product'] = test['product'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Regular code for test begins, use for both arima and LGB for ff prediction   ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['product_category'].fillna(value=test['product_category'].value_counts().index[0],inplace =True)\n",
    "test['product_subcategory'].fillna(value=test['product_subcategory'].value_counts().index[0],inplace =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dropped=test.drop(['product_category','product_subcategory','product','city_name','weekday','monthday','month','year','weekend','ff'],axis=1)\n",
    "test_cat=test.drop(['var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'var_6', 'var_7', 'var_8',\n",
    "       'var_9', 'var_10'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(test_dropped.values)\n",
    "test_dropped = imp.transform(test_dropped.values)\n",
    "test_dropped=pd.DataFrame(test_dropped)\n",
    "test_dropped.columns =['var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'var_6', 'var_7', 'var_8',\n",
    "       'var_9', 'var_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test_dropped.merge(test_cat,left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(['var_4','var_7'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('C:/Users/np8022/Desktop/ZS Hack/ADS TT/Outputs/test_v4(lgb for ff pred_nodis).csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv('C:/Users/np8022/Desktop/ZS Hack/ADS TT/Outputs/train_v4(lgb for ff pred_nodis).csv')\n",
    "test = pd.read_csv('C:/Users/np8022/Desktop/ZS Hack/ADS TT/Outputs/test_v4(lgb for ff pred_nodis).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product                  int64\n",
       "sales                  float64\n",
       "city_name               object\n",
       "product_category        object\n",
       "product_subcategory     object\n",
       "var_1                  float64\n",
       "var_2                  float64\n",
       "var_3                  float64\n",
       "var_5                  float64\n",
       "var_6                  float64\n",
       "var_8                  float64\n",
       "var_9                  float64\n",
       "var_10                 float64\n",
       "weekday                  int64\n",
       "monthday                 int64\n",
       "month                    int64\n",
       "year                     int64\n",
       "weekend                  int64\n",
       "ff                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "MSE = make_scorer(mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(a,b): \n",
    "  return np.sqrt(((a - b) ** 2).mean())\n",
    "from sklearn.metrics import make_scorer\n",
    "RMSE_score = make_scorer(RMSE, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test ={'learning_rate': [0.01,0.1],\n",
    "             'subsample': [0.4,0.7], \n",
    "             'colsample_bytree': [0.7,0.9],\n",
    "             'reg_lambda': [0.1,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test_temp ={'learning_rate': [0.01,0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.stats import randint as sp_randint\n",
    "#from scipy.stats import uniform as sp_uniform\n",
    "#param_test ={'learning_rate': [0.01,0.1,0.8,0.08],\n",
    "             'num_leaves': [6,15,50], \n",
    "             'min_child_samples': [100,300,500], \n",
    "             'min_child_weight': [1e-4, 1e-1, 1, 1e3],\n",
    "             'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############   tuning output  #################\n",
    "params_tuned= {'colsample_bytree': 0.8666214463442921, 'learning_rate': 0.8, 'min_child_samples': 100, 'min_child_weight': 1, 'num_leaves': 50, 'reg_alpha': 5, 'reg_lambda': 0.1, 'subsample': 0.9780808911239147}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "Xd,yd=train.drop('sales',axis=1),train.sales\n",
    "for col in ['product_category','product_subcategory','product','city_name']:\n",
    "            Xd[col] = Xd[col].astype('category')\n",
    "            test[col] = test[col].astype('category')\n",
    "\n",
    "categorical_features_indices = np.where(Xd.dtypes =='object')[0]\n",
    "\n",
    "\n",
    "lgbm = LGBMRegressor(categorical_features = categorical_features_indices,metric='RMSE',random_state=13)\n",
    "\n",
    "\n",
    "iter = 2\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "gs = RandomizedSearchCV(\n",
    "    estimator=lgbm, param_distributions=param_test_temp, \n",
    "    n_iter=iter,\n",
    "    scoring=RMSE_score,\n",
    "    cv=2,\n",
    "    refit=True,\n",
    "    random_state=13,\n",
    "    n_jobs = 1,\n",
    "    verbose=100)\n",
    "gs.fit(Xd, yd)\n",
    "print('Best score: {} params: {} '.format(gs.best_score_, gs.best_params_))\n",
    "\n",
    "pred=[]\n",
    "pred = gs.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_id=pd.read_csv('C:/Users/np8022/Desktop/ZS Hack/ADS TT/Inputs/test_data.csv')\n",
    "\n",
    "s=pd.DataFrame({'id':test_id.id,'sales':pred})\n",
    "s=s.round(2)\n",
    "\n",
    "\n",
    "s.to_csv('C:/Users/np8022/Desktop/ZS Hack/ADS TT/Outputs/LGBM 5_LGB_ffpred_notuning(-73 val rmse learn0.1).csv',index=False)\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
